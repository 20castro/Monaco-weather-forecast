\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[a4paper,top=3.5cm,bottom=3.5cm,left=2.5cm,right=2.5cm,marginparwidth=1.75cm]{geometry}
\usepackage{graphicx}
\usepackage[french,english]{babel} 
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage{fancyhdr}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage[labelfont=bf]{caption}
\usepackage{float}
%\usepackage[sorting=none]{biblatex}

\pagestyle{fancy}
\lhead{Ecole des Mines de Paris\hspace{1cm}---}
\chead{Trimestre Recherche}
\rhead{---\hspace{1cm}Année scolaire 2021-2022}

\setlength\parindent{0px}
\providecommand{\keywords}[1]{\textbf{\textit{Keywords ---}} #1}
\newcommand{\saut}{\vspace{10px}}

\begin{document}

\begin{center}
    \begin{Large}\textbf{Multi-task model to enhance short-term numerical weather predictions in Monaco}\end{Large}
    
    \vspace{1cm}
    \begin{large}\textbf{\underline{D.Castro$^a$}}\end{large}
    
    \vspace{0.5cm}
    a. \href{mailto:david.castro@mines-paristech.fr}{david.castro@mines-paristech.fr}
    \vspace{1cm}
\end{center}

\begin{abstract}
\vspace{5px}
\noindent Within the scope of the Energy Boat Challenge, this paper focuses on short-term solar and wind power 
prediction as a support to renewable-energy powered boats piloting. Considering both model-based numerical
predictions and \emph{in-situ} observations, the implemented models aim for correcting the former by
adding the latter's information.
Such strategy is first motivated by the will to combine numerical models' ability to provide valuable information
over many hours ahead and observations' accuracy.
Although machine and deep learning techniques meant to weather prediction
have recently led to a number of articles, a few take into account several types of inputs.
To that end, a simple baseline model was first investigated, revealing that
numerical predictions can easily be corrected that way and achieving satisfactory performances.
Then, as this work focuses on different tasks, multi-tasks neural networks were implemented in order to
benefit the most from the similarity between solar irradiance and wind predictions. Yet, none of them
managed to beat the linear models' results. It even appears that a simple autoregression on each feature
separately outputs almost as good results as the previous linear regression whereas it ignores numerical
predictions. As a matter of fact, in both cases, the term that seemingly provides the most valuable information
to the prediction is the most recent measurement of the targeted feature. Therefore, autoregression can be
considered the most efficient compromise between the performances and the amount of data needed.
It reveals that the investigated models didn't succeed in capturing numerical predictions added value with respect
to \emph{in-situ} observations. To face that limit, the most relevant next step would be to work with data varying
with both time and space around the targeted location rather than simple timeseries. Doing so would allow
to deal with the numerical models geographical resolution explicitly and to provide a far more complete information
to the model.
\end{abstract}

\saut

\keywords{Weather prediction, Multi-task neural network, NWP correction}

\section*{Notations}

NWP: Numerical Weather Predictions\\
\\
REAN: Reanalyses\\
\\
GHI: Global Horizontal Irradiance\\
\\
WS: Wind Speed\\
\\
WD: Wind Direction\\
\\
SHWW: Significant Height of Wind Waves\\
\\
For a feature F : $\mathrm F (t)$ is the measured value at time $t$, $\hat{\mathrm F}^\mathrm{NWP} (t + dt | t)$ is
the numerical prediction of F at time $t + dt$ knowing the history of the system
and $\hat{\mathrm F}^* (t + dt | t)$, the optimal model-based obtained prediction of F at time $t + dt$ knowing the history.

\section{Introduction}

Accurate and precise solar and wind predictions are critical to the planning and use of renewable energies so that
power production can switch to dispatchable sources when strictly necessary. This concern has led to a large amount of
scientific articles. Many of them seek disruptive ways to predict future weather-related values including deep learning
\cite{zhong_multi-view_2021}.
Present work focuses on the usage of solar and wind power whitin the scope of a renewable energy-powered boats race
-- the Energy Boat Challenge organized each year since 2014 by the Monaco Yacht Club. Therefore, its goal is to provide
solar irradiance and wind speed and direction predictions that would enable either the pilotes to better anticipate
performances or people in charge to adapt the race's schedule. The quality of predictions being less critical than
when it comes to power generation and the purpose being specific, the models implemented are strictly limited to
local and short term prediction, namely over a few hours following present hour and at Monaco.

\saut

\emph{Zhong et al.} proposed an error correction multi-view deep learning network to predict
solar irradiance \cite{zhong_multi-view_2021}. The implemented model learns three different representations of the inputs 
to output one hour ahead irradiance. Similarly, \emph{Gulin et al.} built a predictor-corrector also meant to solar irradiance
forecast \cite{gulin_predictor-corrector_2015}. It tackles the lag and computational effort needed by numerical methods by implementing an observation-based model. It is composed of two parts: the predictor outputs raw
predictions of future solar irradiance as measurements become available while the corrector aims at transforming
the corrector's result to enhance precision.

\saut

In both cases, the models are uniquely based on observations, that is to say they don't rely on a physical model.
They are pure supervised learning algorithms. By contrast, present work introduce a different approach consisting in
merging weather series from different types of sources : Numerical Weather Predictions (NWP) on the one hand and
local measurements on the other. Such method aims at enhancing the available numerical weather prediction by 
adding data from local and intentionnally specific observations in near real-time. A few articles tackling the
enhancement of NWP can be found. For instance, \emph{Huang et al.} rely on the fusion of several numerical models to 
output more accurate predictions than each one of them \cite{huang_integrating_2012}. The issue consisting in the fusion 
of \emph{in-situ} observations is also widely documented since it is the starting point of NWP, called
\emph{data assimilation}: that stands for the computation
of the inital conditions of the forecast model. Thus, it is not a \emph{a posteriori} revision of the model's results but
a part of it. 

\saut

The following work rather answers to the question : can local observations help with NWP correction?
As revealed by \emph{Gulin et al.}, meteorological models complexity and their spatial resolution make NWP
correction an important issue \cite{gulin_predictor-corrector_2015}. This method is very ambitious in the general case and
is made possible here only thanks to the problem's specificity.

\saut

Beyond the previous question, considering the correlation between solar and wind power,
surface temperature and wind waves, this paper also raises the more specific question: can
observation-based NWP correction benefit from a single model gathering all the tasks targeted in comparison with
separate models for each of them? Multi-task models, predicting simultaneously solar irradiance and the wind vector,
were built to this end. \emph{Ruder} \cite{ruder_overview_2017} and \emph{Zang et al.} \cite{zhang_overview_2018}
introduce the key concepts of this type of networks.

\section{Method}

The issue is first to investigate NWP correction thanks to local measurements and secondly to evaluate
the effectiveness of a multi-task model to do so. Both questions need before all to implement baseline models
providing some elements of comparison to latter models and revealing whether even a simple model can
capture some useful information from local measurements to add to NWP.

\saut

Figure \ref{fig:Fig. 1} represent the general structure chosen for the investigated models. In general, for each
explanatory variable, they take
as input the series of the $n$ last measurements and a $2n$-long series of numerical predictions : the $n$ last
predictions (from $t - n + 1$ to $t$) and the $n$ next ones (from $t + 1$ to $t + n$) when the targeted output is
value at time $t + 1, \dots, t + k$ where $k$ is the number of outputs of the task -- equal to $1$ on the figure.
It is clearly preferable to have $k \leq n$ and $n \leq 6$ considering the availability of NWP on live.

% Common model architecture explanations

\vspace{-30px}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{img/structure.pdf}
    \vspace{-30px}
    \caption{\textit{General architecture}}
   \label{fig:Fig. 1}
\end{figure}

\subsection*{Available data}

The implemented models focus on Global Horizontal Irradiance (GHI) as a measurement of solar power
and wind speed and wind direction as a measurement of wind power.
However, in order to avoid working with angles, wind inputs and outputs
take the form of the cartesian coordinates of the wind. Therefore, these are not direct measurements. Temperature will
also be considered but only as input. In other words, no model looks for predicting future temperature since it is
not directly responsible for the amount of renewable energy received, either solar or wind. Yet, it is still expected to
bear useful information to predict GHI or wind. GHI observations used are not direct measurements neither but
computed from satellite data. They are provided by the HelioClim project consisting in satellite-based measurements
of the reflection from the clouds and the ground enabling then to model ground irradiance
\cite{blanc_helioclim_2011}. Considering this method reliability, such observations are nevertheless trusted.

\saut

The numerical weather predictions used to evaluate the following models 
stem from the Europe Center for Medium-Range Weather Forecast (ECMWF), measurements come from a public
Météo-France buoy near Monaco and the SoDa database at the location of the buoy. Reanalyses from SoDa and
the Copernicus programme were also used to check data consistency. The quality control procedure (QCP) achieved
try to follow as much as possible the WMO standards \cite{organization_wmo_guidelines_2021}. Finally,
the considered data range from may to septembre each year between 2016 and 2021 and all have a one hour
time step.

\subsection*{Data consistency}

\begin{figure}[H]
    \centering
    \includegraphics[width=.95\linewidth]{img/shww.png}
    \caption{\textit{Wind wave height}}
   \label{shww}
\end{figure}

Initially, this work was also expected to take into account the significant height of wind waves (SHWW)
and their mean periods (MPWW).
It is indeed an important factor concerning boat piloting. Moreover, wind waves were considered rather than well
first because of geographical criteria and secondly because of their coupled dynamics with respect to wind, making it
a good candidate as part of a multi-task model. However, as illustrated in Figure \ref{shww}, the measurements, the
numerical predictions and the reanalyses were not consistent enough and thus could not be exploited. The two
latter logically fit well because by definition NWP takes part in the computation of reanalyses. Yet, the observations
don't match with them, being generally higher and quite uncorrelated except during peaks.
A possible explanations is that such measurements
are polluted by ship-generated waves, the buoy where the date comes from being close to some crowded shipping
routes. Concerning the mean period of wind waves, the high quantization step size made it unusable neither.

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{img/ws_compare.png}
    \caption{\textit{Wind speed regression}}
   \label{ws_straight}
\end{figure}

On the contrary, as shown for wind speed on Figure \ref{ws_straight}, other features have high correlation levels.
For instance, the temperature correlation coefficient reaches $0.97$ and the GHI coefficient is equal to $0.98$.
These series still raised two QCP issues: filling the gaps in the data and controlling their self-consistencies.
Concerning the latter in particular, it is crucial to check for bounds and gaps between successive values.
This was made following the criteria introduced by \emph{Espinar et al.} \cite{espinar_quality_nodate}.
Finally, one-hour-long gaps were filled using linear interpolation while reanalyses data were used
to complete bigger gaps. Such a choice were made first not to discard to much data -- one gap anywhere in
the data means a much wider loss in terms of training samples -- and secondly considering the low proportion
of samples concerned. For instance, between 2018 and 2020 included, each feature (except GHI) lacks about
200 samples over more than 10,000.

\subsection*{Baseline}

The implemented baseline is meant to assess two different key points : first, the performances allowed by a simple
model that more sophisticated models are to enhance and secondly, the way in which the different data
series individually participate in such performances. To address these issues, the baselines mainly consist in single-output
linear regressions, that is to say outputing the value of a unique feature one hour ahead.
The choice of another machine learning algorithm -- regression random forest or persistence for instance -- have little
impact on targeted metrics.

\saut

In order to assess the impact of each part of the input on the quality of predictions, several architectures were investigated.
The simplest model built consists in an autoregression only based on past measurements of the targeted value.
It is meant to estimate the role of observations. A second basis corresponds to a linear regression taking as input
one hour ahead NWP and trained with measurements as output. That stands for a first attempt to implement a
NWP corrector model. None of these two models follow the structure introduced in Figure \ref{fig:Fig. 1}.

\saut

Remaining baseline models take as input a series of $n$ past measurements, $n$ past NWP, the $n$ next
numerical predictions per feature, for one or several feature -- including at least the targeted one -- and $n = 3$ or
$6$ typically, as explained Figure \ref{fig:Fig. 1}. Several combination of explanatory variables were investigated.
In particular, to estimate how the knowledge of time (date and hour) change the quality of the predictions,
four artificial features were considered as input in some models : the one-year and one-day periodic sines and cosines.

\subsection*{Multi-task models}

In order to answer the second question raised by the introduction, several multi-task models were implemented.
They aim for revealing potential transfer learning between the predictions schemes of the different values targeted.
Regarding the amount of data available, the first multi-task network built contains two or three shared layers and
one or two specific layers per predicted feature.

\saut

As a multi-task model, its training minimizes only one metrics. However, each task leads to one metric, chosen as
the Mean Squared Error (MSE). In order to solve such a multi-objective optimization problem, the chosen loss
function of the overall model L is linear combination of the three losses. Let's note them
$\mathrm{MSE}_{\mathrm T}$
for each task T which can be T = GHI, $\mathrm W_{\mathrm x}$, $\mathrm W_{\mathrm y}$ for instance.
That solution corresponds to the multi-task models state-of-the-art.
Unfortunately, as the three losses can have different order of magnitude, defining
$L = \sum_{\mathrm T \in \mathrm{tasks}} \mathrm{MSE}_{\mathrm T}$ would cause an imbalanced training: the
higher the loss of one task, the more the training would focus on it, resulting in ignoring some of the others. To address
this issue, we have to normalize them by a default value leading us to take:

\[
	L := \sum_{\mathrm T \in \mathrm{tasks}}
	\frac{\mathrm{MSE}_{\mathrm T}}{\mathrm{MSE}^{\mathrm{baseline}}_{\mathrm T}}
\]

By considering the baseline MSE of the task as a normalization factor, having $\mathrm L_{\mathrm{pred}}$ at
the end of a prediction means that on quadratic average over the tasks, the model is
$\sqrt{\frac{\mathrm L_{\mathrm{pred}}}{| \mathrm{tasks} | }}$ better or worse than the baselines.

\vspace{-40px}

\begin{figure}[H]
    \centering
    \includegraphics[width=.9\linewidth]{img/heads.pdf}
    \vspace{-30px}
    \caption{\textit{Multi-task network architecture}}
    \label{fig:Fig. 2}
\end{figure}

% Remaining explanation

\vspace{-30px}

\begin{figure}[H]
    \centering
    \includegraphics[width=.9\linewidth]{img/residual.pdf}
    \vspace{-30px}
    \caption{\textit{Residual network architecture}}
    \label{fig:Fig. 3}
\end{figure}

\saut

The second model implemented is a multi-task \emph{ResNet}, which stands for residual network and consists in adding
the input to the output so that the model learns from the error between NWP and observations rather than observations
themselves directly. The corresponding architecture is represented Figure \ref{fig:Fig. 3} for a single-task model. Yet,
the principle is the same when it comes to a multi-task model. During the training, in the situation represented,
the model is equivalent to a standard network where the labels were replaced by the difference between the
labels and the input, which is the numerical prediction error here.
The last multi-task network evaluated has convolutional shared layers so that it learns an abstract representation of the
data sent to each value-specific head. Its main advantage is take into account the structure of the data, that is to say
that it doesn't flatten the input matrix composed of different type of data series.

% Remaining explanation

\section{Results and discussion}
\subsection*{Baseline}

The results of the baseline models are illustrated through wind speed predictions. Conclusions are very similar
for the other features. Figure \ref{fig:Fig. 4} plots the results of a linear regression in dimension $1$, the explanatory
variable being NWP at time $t$ and the targeted output being the measured value at time $t + 1$. Analyzing both
the NWP empirical error distribution and the one of the
output of the model, such correction mainly removes the systematic bias.
Hence the need for adding past measurements to the input. This is what is done by the model whose results
are represented Figure \ref{fig:Fig. 5}.

% Continuing these explanations

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{img/base.png}
    \caption{\textit{Wind speed simple regression result}}
    \label{fig:Fig. 4}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{img/baseline.png}
    \caption{\textit{Wind speed baseline result}}
    \label{fig:Fig. 5}
\end{figure}

This model corrects bias too but also reduces the standard deviation of the error distribution. In what follows,
as such distributions approximately verify a gaussian law, the attention is mainly directed towards the standard
deviation. First, the bias $\varepsilon_0 = \mathbb E [ \varepsilon ]$ where $\varepsilon$ stands for the error,
needs much less information to be corrected: bias correction is achieved thanks to a simple addition.
Most of the investigated models thus remove it. Secondly, if $\hat \sigma$ is an estimate
of the standard deviation of $\varepsilon$ and $\hat \varepsilon_0$ is the empirical mean
of $\varepsilon$ -- which is the maximum-likelihood estimate of $\varepsilon_0$ --, we have:

\[
	\mathrm{RMSE} = \sqrt{\frac{1}{N} \sum_{i = 1}^N \varepsilon^2_i} \approx \sqrt{ \mathbb E [\varepsilon^2] }
	= \sqrt{\hat \sigma^2 + \hat \varepsilon^2_0}
\]

Therefore, when the a model's bias is indeed negligible, $\mathrm{RMSE} \approx \hat \sigma$.
The previous model is more performant regarding both criteria but its concrete interest
rather lies in the error distribution being sharper.

\saut

However, it is remarkable that an autoregression leads to almost as good results as the previous model, either
considering their empirical error distributions or their RMSE. Figure \ref{fig:Fig. 6} plots the coefficients associated to
each model in order to compare the hidden mechanisms behind such predictions. What appears is first that
the autoregression here is near to a persistence model in addition to bias correction: the predicted output is
approximately a linear function of the observation at time $t$. Secondly, the previous model, called \emph{baseline},
has quite similar coefficients as the autoregression's. The main difference between the two series of coefficients
lies in the intercept: whereas the autoregression has a high one which stands for bias correction, the second model
has a very low intercept since the bias correction is rather computed from future NWP and past observations and NWP.
That reveals the interest of taking into account both measurements and short-term NWP.

\saut

That is also what explains that an autoregressive scheme
is not effective for all features: it leads to bad performances for the GHI
for instance. Yet, it is clear that such a linear regression over NWP and measurements, whose coefficients were
plotted, doesn't benefit the most from both series. It is therefore expected that a non-linear model reaches
better precision and even more a multi-task model which is able to exploit the similarity between the prediction of
the GHI and the wind.

% Almost persistence, that's why it works far worse for ghi --> a bit of luck here but not really interesting in general
% Interpretation (and other factors : n etc)

\begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{img/coef.png}
    \caption{\textit{Wind speed regression coefficients}}
    \label{fig:Fig. 6}
\end{figure}

\subsection*{Multi-task networks}

Each of the multi-task, the residual multi-task and the convolutional multi-task models actually
led to similar results as the baselines. The training generalizes well,
as shown on Figure \ref{fig:Res} and \ref{fig:Conv} and stop
when the loss approximately reaches the baseline performances.
As a matter of fact, the loss function were designed so that the models equal the baseline on quadratic average
over the tasks when the loss reaches 10.

\begin{figure}[H]
\centering
\begin{minipage}{.5\textwidth}
	\centering
	\includegraphics[width=.95\linewidth]{img/restrain.png}
	\captionof{figure}{ResNet training}
	\label{fig:Res}
\end{minipage}%
\begin{minipage}{.5\textwidth}
	\centering
	\includegraphics[width=.95\linewidth]{img/convtrain.png}
	\captionof{figure}{ConvNet training}
	\label{fig:Conv}
\end{minipage}
\end{figure}

\begin{table}[htb]\centering
\begin{tabular}{ccccc}
\toprule
      Feature&NWP RMSE&Baseline RMSE&\multicolumn{2}{c}{Multi-task RMSE}\\\cmidrule{4-5}
      &	 &	&	Ouput 1	&Output 2\\ \midrule
      GHI	&40.70&61.03&	44.32&54.38\\
      $\mathrm W_{\mathrm x}$	&1.97&1.09&1.13&1.36\\
      $\mathrm W_{\mathrm y}$	&1.12&2.24&1.16&1.43\\
      \bottomrule
\end{tabular}
\caption{Multi-task models results}
\label{tab:results}
\end{table}

Table \ref{results} compares the RMSE obtained in the different situations: NWP, linear baseline and convolutional
multi-task network predicting each concerned feature one and two hours ahead. Not only are the multi-task
RMSE higher but they increase fast with the number of values predicted.

\section*{Conclusion and future work}

Finally, multi-tasks neural networks shows unexpectedly bad results and are unable to improve the baseline
performances. The main conclusion that can be drawn is that the implemented models don't manage to fully
benefit from the numerical predictions added value with respect to the observations.

\saut

The most promising perspective would be to take into account the space dimension, that is to say not to take as input
the timeseries of each feature at a specific location -- here Monaco -- but a grid of such values all around the
targeted place for each timestep.
As the adopted strategy focusing on NWP correction was in particular chosen to tackle the geographical resolution
of the numerical models, time-space models can be expected to bring more complete and useful information.
That would especially allow more sophisticated convolutional models.
It would also be interesting to investigate recurrent networks and particularly
LSTM which can learn short-term as well as long-term mechanisms. Yet, the main obstacle remains the amount of data
available which keeps from implementing deep networks.

\section*{Acknowledgements}

\bibliographystyle{unsrt}
\bibliography{references}

\end{document}
